# ğŸ“š Non-LLM Foundation Models: Vision, Audio, Video, Robotics & Scientific

This document tracks foundation models and specialized builders across non-LLM domains: image generation, video synthesis, audio/speech generation, robotics, and scientific/domain-specific models.

## ğŸ¨ Image & Vision Generation Models

### European Image Gen Labs

- [x] ğŸ‡©ğŸ‡ª Black Forest Labs
  - ğŸ¨ FLUX.1 series (12B parameters)
  - ğŸ¨ FLUX.1 Schnell (open-source, fastest)
  - ğŸ¨ FLUX.1 Dev (open-weight)
  - ğŸ¨ FLUX.1 Pro (premium API)
  - ğŸ¨ FLUX 1.1 Pro (ultra mode)
  - ğŸ’° $4B valuation talks (2024)
  - ğŸ‘¥ Founded by ex-Stability AI team

### Multimodal Companies with Image Gen (See LLM-Overview for full details)
- Google (Gemini Diffusion, Veo video)
- OpenAI (DALL-E via GPT-4V)
- Stability AI (Stable Diffusion series)
- Meta (Imagine/Emu image models)

---

## ğŸ¬ Video Generation Models

### To Research:
- OpenAI Sora
- Midjourney (video expansion)
- Pika
- Luma AI
- Synthesia
- HeyGen
- D-ID
- Meta Emu Video (beyond Runway)
- Google Veo
- Stability AI Stable Video Diffusion

---

## ğŸ™ï¸ Audio & Speech Foundation Models

- [x] ğŸ‡ºğŸ‡¸ Play.ht
  - ğŸ¤– PlayHT2.0 (proprietary speech foundation model)
  - ğŸ¤– Play3.0-mini (speech generation)
  - ğŸ™ï¸ Trained on 1M+ hours of multilingual speech
  - ğŸ—£ï¸ Voice cloning (3-10 seconds needed)
  - ğŸŒ 100+ languages with emotional expressiveness
  - ğŸ† First speech generation models with emotional expressiveness at scale

### To Research:
- ElevenLabs (voice synthesis)
- Suno (music generation)
- Udio (music generation)
- Google NotebookLM audio (with Gemini)
- OpenAI Whisper (speech-to-text, already large foundation model)

---

## ğŸ‘ï¸ Computer Vision Foundation Models (Non-generative)

- [x] ğŸ‡¨ğŸ‡³ Megvii
  - ğŸ‘ï¸ Computer vision foundation models (YOLOX, BEVDepth)
  - ğŸ‘ï¸ Multi-modal foundation models (research focus)
  - ğŸ“Š Object detection, 3D perception, autonomous driving
  - ğŸš— BEVDepth for autonomous vehicle perception

---

## ğŸ¤– Robotics & Embodied AI Foundation Models

### To Research:
- Tesla (visual + motor models for Optimus humanoid robot)
- Figure AI (humanoid robot foundation models)
- 1X Technologies (robot visual/motor models)
- Boston Dynamics (robot AI models)
- Sanctuary AI (humanoid robot AI)
- Google DeepMind (robot learning, RTFN models)

---

## ğŸ§¬ Scientific & Biological Foundation Models

### Protein & Molecular:

- DeepMind/Google (AlphaFold series - protein structure prediction)
- OpenProtein Foundation (protein language models)
- Genentech/Roche (molecule/drug discovery)
- SchrÃ¶dinger (molecular modeling foundation models)
- Exscientia (AI drug discovery foundation models)

### Earth Science & Remote Sensing:

- [x] ğŸ‡ºğŸ‡¸ Allen Institute for AI - OlmoEarth
  - ğŸŒ Multimodal earth observation foundation model
  - ğŸ›°ï¸ Satellite/sensor data foundation model
  - ğŸ“Š First open end-to-end earth observation solution
  - ğŸ“Š Trained on 10TB+ earth observation data
  - ğŸ—ºï¸ Released November 4, 2025

### To Research:
- NASA/JPL (satellite data models)
- ESA (European satellite data models)
- NOAA (climate/weather models)

---

## ğŸ¥ Medical & Healthcare Specialized Foundation Models

### To Research:
- Google DeepMind (medical imaging)
- Tempus (cancer/health AI)
- Insitro (drug discovery)
- IBM (medical LLMs + imaging)

---

## ğŸ“Š Tabular & Specialized Data Foundation Models

- [x] ğŸ‡©ğŸ‡ª University of Freiburg
  - ğŸ‘¨â€ğŸ”¬ Frank Hutter (Professor) - foundation models for tabular data
  - ğŸ¤– TabPFN v2 (published Nature 2025)
    - 1M+ downloads
    - Bayesian approach, works "out of the box" on time-series
    - Orders of magnitude more data than v1
    - Sets new SOTA on key time-series benchmarks
  - ğŸ”§ CAAFE (first method for automated feature engineering with LLMs)
  - ğŸ›ï¸ ELLIS unit Freiburg, OpenEuroLLM research participation

---

## ğŸ“Š Infrastructure & Dataset Providers (Supporting Foundation Models)

- [x] ğŸ‡©ğŸ‡ª LAION (Large-scale AI Open Network)
  - ğŸ“Š LAION-5B, LAION-400M (massive datasets)
  - ğŸ“Š Re-LAION-5B (Aug 2024 release)
  - ğŸ¨ Enabled Stable Diffusion, Imagen training
  - ğŸ›ï¸ German nonprofit
  - âš–ï¸ Won legal case on TDM exceptions (Sept 2024)
  - â„¹ï¸ Note: Dataset provider, not a foundation model builder, but critical infrastructure

---

## ğŸ“ˆ Summary

**Total Non-LLM Entries: 10+** (to be expanded with research)

**Categories:**
- ğŸ¨ Image Generation: 1 (Black Forest Labs) + 4 multimodal companies
- ğŸ¬ Video Generation: 10+ to research
- ğŸ™ï¸ Audio/Speech: 1 (Play.ht) + 5+ to research
- ğŸ‘ï¸ Computer Vision: 1 (Megvii)
- ğŸ¤– Robotics: 5+ to research
- ğŸ§¬ Scientific/Biological: 1 (OlmoEarth) + 5+ to research
- ğŸ¥ Medical: 4+ to research
- ğŸ“Š Tabular Data: 1 (TabPFN)
- ğŸ“Š Infrastructure: 1 (LAION)

**Next Steps:**
- Research and add video generation labs
- Research and add audio/music generation labs
- Research and add robotics/embodied AI labs
- Research and add scientific/biological foundation models
- Research and add medical foundation models
