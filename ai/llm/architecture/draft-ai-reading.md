# AI Reading List

A curated collection of AI/ML articles, blog posts, tutorials, and resources.

## üìö Reading List

| Title | Type | Source | URL |
|-------|------|--------|-----|
| **Haohuan's Recommendations** | | | |
| Pallas Design ‚Äî JAX documentation | Documentation | JAX | https://docs.jax.dev/en/latest/pallas/design/design.html |
| Autodidax: JAX core from scratch ‚Äî JAX documentation | Tutorial | JAX | https://docs.jax.dev/en/latest/autodidax.html |
| GSPMD: General and Scalable Parallelization for ML Computation Graphs | Paper | arXiv | [2105.04663](https://arxiv.org/abs/2105.04663) |
| Cloud TPU Multislice Overview [Public Preview] | Documentation | Google Cloud | https://cloud.google.com/tpu/docs/multislice-introduction |
| **From Old List** | | | |
| A brief history of TensorFlow Extended (TFX) | Blog | TensorFlow | https://blog.tensorflow.org/2020/09/brief-history-of-tensorflow-extended-tfx.html |
| An Introduction To HuggingFace Transformers for NLP | Tutorial | Weights & Biases | https://wandb.ai/int_pb/huggingface/reports/An-Introduction-To-HuggingFace-Transformers-for-NLP--VmlldzoyOTgzMjI5 |
| Function calling and other API updates | Blog | OpenAI | https://openai.com/blog/function-calling-and-other-api-updates |
| Neural Network Architectures Guide | Tutorial | V7 Labs | https://www.v7labs.com/blog/neural-network-architectures-guide |
| Neural Network Architectures | Article | Towards Data Science | https://towardsdatascience.com/neural-network-architectures-156e5bad51ba |
| Information Theory, Inference and Learning Algorithms | Book | David MacKay | https://www.inference.org.uk/mackay/itila/ |
| Adversarial Attacks on LLMs | Blog | Lil'Log | https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/ |
| At the Intersection of LLMs and Kernels - Research Roundup | Article | - | - |
| The Transient Nature of Emergent In-Context Learning in Transformers | Paper | arXiv | [2311.08360](https://arxiv.org/abs/2311.08360) |
| AI at Scale | Research | Microsoft Research | https://www.microsoft.com/en-us/research/project/ai-at-scale/ |
| ZeRO & DeepSpeed: New system optimizations enable training models with over 100 billion parameters | Blog | Microsoft Research | https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/ |
| Accelerate PyTorch workloads with PyTorch/XLA | Video | YouTube | - |
| FunSearch: Making new discoveries in mathematical sciences using Large Language Models | Research | Google DeepMind | https://deepmind.google/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/ |
| What I Wish Someone Had Told Me | Blog | Sam Altman | https://blog.samaltman.com/what-i-wish-someone-had-told-me |
| 10 Noteworthy AI Research Papers of 2023 | Article | - | - |
| llm-course: Course to get into Large Language Models (LLMs) with roadmaps and Colab notebooks | GitHub | mlabonne | https://github.com/mlabonne/llm-course |
| Awesome-CUDA: A list of useful libraries and resources for CUDA development | GitHub | Erkaman | https://github.com/Erkaman/Awesome-CUDA |
| Hands-On GPU Programming with Python and CUDA | GitHub | Packt Publishing | https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA |
| NVIDIA cuda-samples: Samples for CUDA Developers | GitHub | NVIDIA | https://github.com/NVIDIA/cuda-samples |
| Integrating NVIDIA TensorRT-LLM with the Databricks Inference Stack | Blog | Databricks | - |
| My Fave New Podcasts of 2023 | Blog | - | - |
| Introducing Mixtral 8x7B with Databricks Model Serving | Blog | Databricks | - |
| Getting Started with Mixtral 8X7B | Tutorial | Pinecone | https://www.pinecone.io/learn/mixtral-8x7b/ |
| Welcome to the ü§ó Deep Reinforcement Learning Course | Course | Hugging Face | https://huggingface.co/learn/deep-rl-course/en/unit0/introduction |
| What do I need to know about Mamba in the ML world | Article | - | - |
| The promise and challenges of crypto + AI applications | Article | - | - |
| Large Language Models, How to Train Them, and xAI's Grok | Article | - | - |
| Practical Tips for Finetuning LLMs Using LoRA (Low-Rank Adaptation) | Tutorial | - | - |
| Human-like systematic generalization through a meta-learning neural network | Paper | Nature | https://www.nature.com/articles/s41586-023-06668-3 |
| OpenAI: Facts from a Weekend | Article | LessWrong | - |
| A checklist for switching to open source ML models | Guide | - | - |
| Distill ‚Äî Latest articles about machine learning | Website | Distill | https://distill.pub/ |
| Research Papers in January 2024 | Newsletter | Sebastian Raschka | - |
| V-JEPA: The next step toward advanced machine intelligence | Research | Meta | https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/ |
| Improving LoRA: Implementing Weight-Decomposed Low-Rank Adaptation (DoRA) from Scratch | Tutorial | - | - |
| ML-YouTube-Courses: Discover the latest machine learning / AI courses on YouTube | GitHub | dair-ai | https://github.com/dair-ai/ML-YouTube-Courses |
| SolidGoldMagikarp (plus, prompt generation) | Article | LessWrong | - |
| Explaining SolidGoldMagikarp by looking at it from random directions | Article | LessWrong | - |
| Mamba No. 5 (A Little Bit Of‚Ä¶) | Article | Sparse Notes | - |
| Mamba: The Easy Way | Tutorial | - | - |
| Mamba: The Hard Way | Tutorial | - | - |
| q star info.pdf | Document | Google Drive | - |
| Ilya Sutskever: The brain behind ChatGPT | Article | - | - |
| Training great LLMs entirely from ground zero in the wilderness as a startup | Blog | Yi Tay | https://www.yitay.net/blog/training-great-llms-entirely-from-ground-zero-in-the-wilderness |
| Ben Thimpson podcast | Podcast | - | - |
| Is Cosine-Similarity of Embeddings Really About Similarity? | Paper | arXiv | [2403.05440](https://arxiv.org/abs/2403.05440) |
| OpenXLA is available now to accelerate and simplify machine learning | Blog | Google Open Source | https://opensource.googleblog.com/2023/03/openxla-is-ready-to-accelerate-and-simplify-ml-development.html |
| Many-shot jailbreaking | Research | Anthropic | https://www.anthropic.com/research/many-shot-jailbreaking |
| The Data Center is the New Compute Unit: Nvidia's Vision for System-Level Scaling | Article | - | - |
| Techniques for training large neural networks | Guide | OpenAI | https://openai.com/index/techniques-for-training-large-neural-networks/ |
| The pitfalls of next-token prediction | Paper | arXiv | [2403.06963](https://arxiv.org/abs/2403.06963) |
| The N Implementation Details of RLHF with PPO | Blog | ICLR Blogposts 2024 | https://iclr-blogposts.github.io/2024/blog/the-n-implementation-details-of-rlhf-with-ppo/ |
| Dear VC's, please stop throwing money at AI founders with no commercial plan, besides AGI | Opinion | - | - |
| Are all LLMs really 1.58 bits? Inference at 4x the speed or more? | Article | - | - |
| Medusa: Simple framework for accelerating LLM generation with multiple decoding heads | Research | - | - |
| Ilya's recom to Carmack | Reference | - | - |
| Speech and Language Processing | Textbook | - | - |
| We need to talk about Agents... | Article | - | - |
| What can LLMs never do? | Article | Rohit Krishnan | - |
| How to Optimize a CUDA Matmul Kernel for cuBLAS-like Performance: a Worklog | Tutorial | - | - |
| Quantizing deep convolutional networks for efficient inference: A whitepaper | Paper | arXiv | [1806.08342](https://arxiv.org/abs/1806.08342) |
| Claude's Character | Research | Anthropic | https://www.anthropic.com/research/claude-character |
| Quantization aware training | Documentation | TensorFlow Model Optimization | https://www.tensorflow.org/model_optimization/guide/quantization/training |
| Scalable MatMul-free Language Modeling | Paper | arXiv | [2406.02528](https://arxiv.org/abs/2406.02528) |
| Introducing Apple's On-Device and Server Foundation Models | Research | Apple ML Research | - |
| Qwen 2: a story of Alibaba vs Meta | Article | Rick Lamers | - |
| OpenVLA: An Open-Source Vision-Language-Action Model | Research | - | - |
| Transformer Architecture: The Positional Encoding | Blog | Amirhossein Kazemnejad | https://kazemnejad.com/blog/transformer_architecture_positional_encoding/ |
| [RFC] PagedAttention Support | GitHub Issue | pytorch/pytorch | - |
| Extrinsic Hallucinations in LLMs | Blog | Lil'Log | https://lilianweng.github.io/posts/2024-07-07-hallucination/ |
| Meta PyTorch Team 2024 H2 Roadmaps | Mailing List | PyTorch Developer | - |
| Prime Intellect: OpenDiLoCo | Research | Prime Intellect | - |
| X OpenDiLoCo | Tweet | X/Twitter | - |
| Apple Foundation Model | Research | Apple | - |
| Why do LLM input tokens cost less than output tokens? | Explainer | - | - |
| Welcome to Model Optimizer (ModelOpt) documentation! | Documentation | NVIDIA | https://nvidia.github.io/TensorRT-Model-Optimizer/ |
| x.com Meta Agent | Tweet | X/Twitter | - |
| Triton Architecture | Documentation | NVIDIA Triton Inference Server | https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html |
| TensorRT-LLM Architecture | Documentation | TensorRT-LLM | https://nvidia.github.io/TensorRT-LLM/architecture/overview.html |
| What's Really Going On in Machine Learning? Some Minimal Models | Article | Stephen Wolfram | - |
| Fire-Flyer AI-HPC: A Cost-Effective Software-Hardware Co-Design for Deep Learning | Paper | arXiv | [2408.14158](https://arxiv.org/abs/2408.14158) |
| awesome-dspy | GitHub | tom-doerr | https://github.com/tom-doerr/awesome-dspy |
| Azure/kaito: Kubernetes AI Toolchain Operator | GitHub | Azure | https://github.com/Azure/kaito |
| TensorRT explained | Article | aijobs.net | - |
| The Evolution of Multimodal Model Architectures | Paper | arXiv | [2405.17927](https://arxiv.org/abs/2405.17927) |
| Dynamic sparse attention | Tweet | X/Twitter | - |
| $2 H100s: How the GPU Bubble Burst | Article | Eugene Cheah | - |
| vLLM v0.6.0: 2.7x Throughput Improvement and 5x Latency Reduction | Blog | vLLM | https://blog.vllm.ai/2024/09/05/perf-update.html |
| Making Deep Learning go Brrrr From First Principles | Tutorial | - | - |
| Glow | Framework | - | - |
| ML Compilers Part 2: An Overview of Graph Optimizations | Blog | FuzzyWare | - |
| GPU-Guide: Graphics Processing Unit (GPU) Architecture Guide | GitHub | mikeroyal | https://github.com/mikeroyal/GPU-Guide |
| Blog list | Collection | - | - |
| GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models | Paper | arXiv | [2410.05229](https://arxiv.org/abs/2410.05229) |
| Distilling Llama3.1 8B into 1B in torchtune | Tutorial | PyTorch | https://pytorch.org/blog/llama-into-torchtune/ |
| Archive ‚Ä¢ AI News ‚Ä¢ Buttondown | Newsletter | AI News | - |
| Hugging Face ‚Äì Blog | Blog | Hugging Face | - |
| vllm quantization | Documentation | vLLM | https://docs.vllm.ai/en/latest/features/quantization/index.html |
| how-to-optim-algorithm-in-cuda: how to optimize some algorithm in cuda | GitHub | BBuf | https://github.com/BBuf/how-to-optim-algorithm-in-cuda |
| INTELLECT-1 Release The First Globally Trained 10B Parameter Model | Announcement | Prime Intellect | - |
| INTELLECT_1_Technical_Report.pdf | Technical Report | PrimeIntellect-ai | - |
| Making WAF ML models go brrr: saving decades of processing time | Blog | Cloudflare | - |
| Claude 3.5 Sonnet Insane Coding Ability | Article | - | - |
| AI-Engineering.academy: Mastering Applied AI, One Concept at a Time | GitHub | adithya-s-k | https://github.com/adithya-s-k/AI-Engineering.academy |
| Late Takes on OpenAI o1 | Article | - | - |
| Ways to use torch.compile | Blog | ezyang's blog | - |
| On AI for developer productivity | Article | - | - |
| Scaling test-time compute | Demo | Hugging Face Space | - |
| Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters | Paper | arXiv | [2408.03314](https://arxiv.org/abs/2408.03314) |
| Building effective agents | Guide | Anthropic | https://www.anthropic.com/research/building-effective-agents |
| 2024 best papers | Collection | - | - |
| Learning CUDA by optimizing softmax: A worklog | Tutorial | Maharshi's blog | - |
| Reinforcement learning from AI feedback (RLAIF): Complete overview | Tutorial | SuperAnnotate | - |
| Agents | Article | - | - |
| Video Generation Models Explosion 2024 | Article | Yen-Chen Lin | - |
| Tenstorrent Blackhole, Grendel, And Buda ‚Äì A Scale Out Architecture | Analysis | SemiAnalysis | - |
| Dario Amodei ‚Äî On DeepSeek and Export Controls | Article | - | - |
| Foundations of Large Language Models (this is a book) | Book | arXiv | [2501.09223](https://arxiv.org/abs/2501.09223) |
| How multi-node inference works for massive LLMs like DeepSeek-R1 | Blog | Baseten | - |
| Understanding Peak, Max-Achievable & Delivered FLOPs, Part 1 | Tutorial | ROCm Blogs | - |
| LLMËÆ≠ÁªÉÁªàÊûÅÊåáÂçó | The Ultra-Scale Playbook | Guide | Hugging Face Space | - |
| Minions: Cost-efficient Collaboration Between On-device and Cloud Language Models | Paper | arXiv | [2502.15964](https://arxiv.org/abs/2502.15964) |
| Circuit Tracing: Revealing Computational Graphs in Language Models | Research | - | - |
| On the Biology of a Large Language Model | Article | - | - |
| TAO: Using test-time compute to train efficient LLMs without labeled data | Blog | Databricks | - |
| RLHF Book by Nathan Lambert | Book | Nathan Lambert | https://rlhfbook.com/ |
| CUTLASS Tutorial: Writing GEMM Kernels Using Tensor Memory For NVIDIA¬Æ Blackwell GPUs | Tutorial | Colfax Research | - |
| The Way of Code | Article | Rick Rubin | - |
| Why I No Longer Recommend RAG for Autonomous Coding Agents | Opinion | - | - |
| xAI's Grok 4: The tension of frontier performance with a side of Elon favoritism | Analysis | - | - |
| Awesome-ML-SYS-Tutorial: My learning notes/codes for ML SYS | GitHub | zhaochenyang20 | https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial |
| The Ultra-Scale Playbook | Guide | Hugging Face Space | - |
| TensorRT-LLM Architecture | Documentation | TensorRT-LLM | - |
| A Manual Implementation of Quantization in PyTorch - Single Layer | Tutorial | Hexo | - |
| Measuring the environmental impact of AI inference | Blog | Google Cloud | - |
| How to Think About GPUs | Guide | How To Scale Your Model | - |
| A Primer on LLM Post-Training | Tutorial | PyTorch | - |
| AI 2027 | Prediction | - | - |
| How To Scale Your Model | Guide | - | - |
| Getting Started With CuTe | Documentation | NVIDIA CUTLASS | - |
| AMD Data Center GPUs Explained: MI250X, MI300X, MI350X and Beyond | Guide | - | - |
| GPU L2 Cache Persistence | Blog | simons blog | - |
| RedOne: Revealing Domain-specific LLM Post-Training in Social Networking Services | Paper | arXiv | [2507.10605](https://arxiv.org/abs/2507.10605) |
| The Big LLM Architecture Comparison | Article | - | - |
| The Training Imperative | Article | - | - |
| checkpoint-engine: Checkpoint-engine is a simple middleware to update model weights | GitHub | MoonshotAI | https://github.com/MoonshotAI/checkpoint-engine |
| Improving Cursor Tab With RL | Blog | Cursor | https://cursor.com/blog/tab-rl |
| Paged Attention from First Principles: A View Inside vLLM | Blog | Hamza's Blog | - |
| Speculative cascades ‚Äî A hybrid approach for smarter, faster LLM inference | Article | - | - |
| Cornell Virtual Workshop: Understanding GPU Architecture | Workshop | Cornell | - |
| Disaggregated Inference at Scale with PyTorch & vLLM | Tutorial | PyTorch | - |
| SGLang v0.4: Zero-Overhead Batch Scheduler, Cache-Aware Load Balancer | Blog | LMSYS Org | - |
| sglang pdf | Document | - | - |
| Tree Attention: Topology-aware Decoding for Long-Context Attention on GPU clusters | Paper | arXiv | [2408.04093](https://arxiv.org/abs/2408.04093) |
| Will Amazon S3 Vectors Kill Vector Databases‚Äîor Save Them? | Article | Zilliz blog | - |
| Post-training 101 | Tutorial | Tokens for Thoughts | - |
| Online RL for Cursor Tab | Blog | Cursor | https://cursor.com/blog/tab-rl |
| Stanford CRFM | Research Group | Stanford | https://crfm.stanford.edu/ |
| Surprisingly Fast AI-Generated Kernels We Didn't Mean to Publish (Yet) | Research | Stanford Scaling Intelligence Lab | - |
| Advanced RAG Techniques: an Illustrated Overview | Article | Towards AI | - |
| Modular Manifolds | Research | Thinking Machines Lab | - |
| Inside NVIDIA GPUs: Anatomy of high performance matmul kernels | Tutorial | Aleksa Gordiƒá | - |
| Weight Transfer for RL Post-Training in under 2 seconds | Article | - | - |
| Deploying DeepSeek with PD Disaggregation and Large-Scale Expert Parallelism on 96 H100 GPUs | Blog | LMSYS Org | - |
| LLM evolution | Article | - | - |
| Qwen 3 | Announcement | Qwen | - |
| flash decoding | Research | - | - |
| Dissecting Batching Effects in GPT Inference | Analysis | - | - |
| How to think about GPU | Guide | - | - |
