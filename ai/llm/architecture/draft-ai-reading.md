# AI Reading List

A curated collection of AI/ML articles, blog posts, tutorials, and resources.

## üìö Reading List

| Title | Type | Source | URL |
|-------|------|--------|-----|
| **Haohuan's Recommendations** | | | |
| Pallas Design ‚Äî JAX documentation | Documentation | JAX | [Link](https://docs.jax.dev/en/latest/pallas/design/design.html) |
| Autodidax: JAX core from scratch ‚Äî JAX documentation | Tutorial | JAX | [Link](https://docs.jax.dev/en/latest/autodidax.html) |
| GSPMD: General and Scalable Parallelization for ML Computation Graphs | Paper | arXiv | [2105.04663](https://arxiv.org/abs/2105.04663) |
| Cloud TPU Multislice Overview [Public Preview] | Documentation | Google Cloud | [Link](https://cloud.google.com/tpu/docs/multislice-introduction) |
| **From Old List** | | | |
| A brief history of TensorFlow Extended (TFX) | Blog | TensorFlow | [Link](https://blog.tensorflow.org/2020/09/brief-history-of-tensorflow-extended-tfx.html) |
| An Introduction To HuggingFace Transformers for NLP | Tutorial | Weights & Biases | [Link](https://wandb.ai/int_pb/huggingface/reports/An-Introduction-To-HuggingFace-Transformers-for-NLP--VmlldzoyOTgzMjI5) |
| Function calling and other API updates | Blog | OpenAI | [Link](https://openai.com/blog/function-calling-and-other-api-updates) |
| Neural Network Architectures Guide | Tutorial | V7 Labs | [Link](https://www.v7labs.com/blog/neural-network-architectures-guide) |
| Neural Network Architectures | Article | Towards Data Science | [Link](https://towardsdatascience.com/neural-network-architectures-156e5bad51ba) |
| Information Theory, Inference and Learning Algorithms | Book | David MacKay | [Link](https://www.inference.org.uk/mackay/itila/) |
| Adversarial Attacks on LLMs | Blog | Lil'Log | [Link](https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/) |
| At the Intersection of LLMs and Kernels - Research Roundup | Article | Charles Frye | [Link](https://charlesfrye.github.io/programming/2023/11/10/llms-systems.html) |
| The Transient Nature of Emergent In-Context Learning in Transformers | Paper | arXiv | [2311.08360](https://arxiv.org/abs/2311.08360) |
| AI at Scale | Research | Microsoft Research | [Link](https://www.microsoft.com/en-us/research/project/ai-at-scale/) |
| ZeRO & DeepSpeed: New system optimizations enable training models with over 100 billion parameters | Blog | Microsoft Research | [Link](https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/) |
| Accelerate PyTorch workloads with PyTorch/XLA | Video | YouTube | [Link](https://io.google/2024/explore/6ad3f13a-9255-4ae1-8dd2-d89acada10c1/) |
| FunSearch: Making new discoveries in mathematical sciences using Large Language Models | Research | Google DeepMind | [Link](https://deepmind.google/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/) |
| What I Wish Someone Had Told Me | Blog | Sam Altman | [Link](https://blog.samaltman.com/what-i-wish-someone-had-told-me) |
| 10 Noteworthy AI Research Papers of 2023 | Article | - | [Link](https://magazine.sebastianraschka.com/p/10-ai-research-papers-2023) |
| llm-course: Course to get into Large Language Models (LLMs) with roadmaps and Colab notebooks | GitHub | mlabonne | [Link](https://github.com/mlabonne/llm-course) |
| Awesome-CUDA: A list of useful libraries and resources for CUDA development | GitHub | Erkaman | [Link](https://github.com/Erkaman/Awesome-CUDA) |
| Hands-On GPU Programming with Python and CUDA | GitHub | Packt Publishing | [Link](https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA) |
| NVIDIA cuda-samples: Samples for CUDA Developers | GitHub | NVIDIA | [Link](https://github.com/NVIDIA/cuda-samples) |
| Integrating NVIDIA TensorRT-LLM with the Databricks Inference Stack | Blog | Databricks | [Link](https://www.databricks.com/blog/Integrating-NVIDIA-TensorRT-LLM) |
| My Fave New Podcasts of 2023 | Blog | - | - |
| Introducing Mixtral 8x7B with Databricks Model Serving | Blog | Databricks | [Link](https://www.databricks.com/blog/introducing-mixtral-8x7b) |
| Getting Started with Mixtral 8X7B | Tutorial | Pinecone | [Link](https://www.pinecone.io/learn/mixtral-8x7b/) |
| Welcome to the ü§ó Deep Reinforcement Learning Course | Course | Hugging Face | [Link](https://huggingface.co/learn/deep-rl-course/en/unit0/introduction) |
| What do I need to know about Mamba in the ML world | Article | - | [Link](https://hamel.dev/blog/posts/mamba/) |
| The promise and challenges of crypto + AI applications | Article | - | [Link](https://vitalik.eth.limo/general/2024/01/30/cryptoai.html) |
| Large Language Models, How to Train Them, and xAI's Grok | Article | - | [Link](https://chamath.substack.com/p/large-language-models-how-to-train) |
| Practical Tips for Finetuning LLMs Using LoRA (Low-Rank Adaptation) | Tutorial | - | [Link](https://magazine.sebastianraschka.com/p/practical-tips-for-finetuning-llms) |
| Human-like systematic generalization through a meta-learning neural network | Paper | Nature | [Link](https://www.nature.com/articles/s41586-023-06668-3) |
| OpenAI: Facts from a Weekend | Article | LessWrong | [Link](https://www.lesswrong.com/posts/KXHMCH7wCxrvKsJyn/openai-facts-from-a-weekend) |
| A checklist for switching to open source ML models | Guide | - | [Link](https://www.baseten.co/blog/a-checklist-for-switching-to-open-source-ml-models/) |
| Distill ‚Äî Latest articles about machine learning | Website | Distill | [Link](https://distill.pub/) |
| Research Papers in January 2024 | Newsletter | Sebastian Raschka | [Link](https://magazine.sebastianraschka.com/p/research-papers-in-january-2024) |
| V-JEPA: The next step toward advanced machine intelligence | Research | Meta | [Link](https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/) |
| Improving LoRA: Implementing Weight-Decomposed Low-Rank Adaptation (DoRA) from Scratch | Tutorial | - | [Link](https://magazine.sebastianraschka.com/p/lora-and-dora-from-scratch) |
| ML-YouTube-Courses: Discover the latest machine learning / AI courses on YouTube | GitHub | dair-ai | [Link](https://github.com/dair-ai/ML-YouTube-Courses) |
| SolidGoldMagikarp (plus, prompt generation) | Article | LessWrong | [Link](https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation) |
| Explaining SolidGoldMagikarp by looking at it from random directions | Article | LessWrong | [Link](https://www.lesswrong.com/posts/jbi9kxhb4iCQyWG9Y/explaining-solidgoldmagikarp-by-looking-at-it-from-random) |
| Mamba No. 5 (A Little Bit Of‚Ä¶) | Article | Sparse Notes | [Link](https://jameschen.io/jekyll/update/2024/02/12/mamba.html) |
| Mamba: The Easy Way | Tutorial | - | [Link](https://jackcook.com/2024/02/23/mamba.html) |
| Mamba: The Hard Way | Tutorial | - | [Link](https://srush.github.io/annotated-mamba/hard.html) |
| q star info.pdf | Document | Google Drive | - |
| Ilya Sutskever: The brain behind ChatGPT | Article | - | [Link](https://journeymatters.ai/ilya-the-brain-behind-chatgpt/) |
| Training great LLMs entirely from ground zero in the wilderness as a startup | Blog | Yi Tay | [Link](https://www.yitay.net/blog/training-great-llms-entirely-from-ground-zero-in-the-wilderness) |
| Ben Thimpson podcast | Podcast | - | - |
| Is Cosine-Similarity of Embeddings Really About Similarity? | Paper | arXiv | [2403.05440](https://arxiv.org/abs/2403.05440) |
| OpenXLA is available now to accelerate and simplify machine learning | Blog | Google Open Source | [Link](https://opensource.googleblog.com/2023/03/openxla-is-ready-to-accelerate-and-simplify-ml-development.html) |
| Many-shot jailbreaking | Research | Anthropic | [Link](https://www.anthropic.com/research/many-shot-jailbreaking) |
| The Data Center is the New Compute Unit: Nvidia's Vision for System-Level Scaling | Article | - | [Link](https://www.fabricatedknowledge.com/p/the-data-center-is-the-new-compute) |
| Techniques for training large neural networks | Guide | OpenAI | [Link](https://openai.com/index/techniques-for-training-large-neural-networks/) |
| The pitfalls of next-token prediction | Paper | arXiv | [2403.06963](https://arxiv.org/abs/2403.06963) |
| The N Implementation Details of RLHF with PPO | Blog | ICLR Blogposts 2024 | [Link](https://iclr-blogposts.github.io/2024/blog/the-n-implementation-details-of-rlhf-with-ppo/) |
| Dear VC's, please stop throwing money at AI founders with no commercial plan, besides AGI | Opinion | - | - |
| Are all LLMs really 1.58 bits? Inference at 4x the speed or more? | Article | - | [Link](https://learning-exhaust.hashnode.dev/are-all-large-language-models-really-in-158-bits) |
| Medusa: Simple framework for accelerating LLM generation with multiple decoding heads | Research | - | [Link](https://github.com/FasterDecoding/Medusa) |
| Ilya's recom to Carmack | Reference | - | - |
| Speech and Language Processing | Textbook | - | [Link](https://web.stanford.edu/~jurafsky/slp3/) |
| We need to talk about Agents... | Article | - | - |
| What can LLMs never do? | Article | Rohit Krishnan | [Link](https://www.strangeloopcanon.com/p/what-can-llms-never-do) |
| How to Optimize a CUDA Matmul Kernel for cuBLAS-like Performance: a Worklog | Tutorial | - | [Link](https://siboehm.com/articles/22/CUDA-MMM) |
| Quantizing deep convolutional networks for efficient inference: A whitepaper | Paper | arXiv | [1806.08342](https://arxiv.org/abs/1806.08342) |
| Claude's Character | Research | Anthropic | [Link](https://www.anthropic.com/research/claude-character) |
| Quantization aware training | Documentation | TensorFlow Model Optimization | [Link](https://www.tensorflow.org/model_optimization/guide/quantization/training) |
| Scalable MatMul-free Language Modeling | Paper | arXiv | [2406.02528](https://arxiv.org/abs/2406.02528) |
| Introducing Apple's On-Device and Server Foundation Models | Research | Apple ML Research | [Link](https://machinelearning.apple.com/research/introducing-apple-foundation-models) |
| Qwen 2: a story of Alibaba vs Meta | Article | Rick Lamers | [Link](https://codingwithintelligence.com/p/qwen-2-a-story-of-alibaba-vs-meta) |
| OpenVLA: An Open-Source Vision-Language-Action Model | Research | - | [Link](https://openvla.github.io/) |
| Transformer Architecture: The Positional Encoding | Blog | Amirhossein Kazemnejad | [Link](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/) |
| [RFC] PagedAttention Support | GitHub Issue | pytorch/pytorch | [Link](https://github.com/pytorch/pytorch/issues/121465) |
| Extrinsic Hallucinations in LLMs | Blog | Lil'Log | [Link](https://lilianweng.github.io/posts/2024-07-07-hallucination/) |
| Meta PyTorch Team 2024 H2 Roadmaps | Mailing List | PyTorch Developer | - |
| Prime Intellect: OpenDiLoCo | Research | Prime Intellect | [Link](https://www.primeintellect.ai/blog/opendiloco) |
| X OpenDiLoCo | Tweet | X/Twitter | - |
| Apple Foundation Model | Research | Apple | [Link](https://machinelearning.apple.com/research/apple-intelligence-foundation-language-models) |
| Why do LLM input tokens cost less than output tokens? | Explainer | - | [Link](https://peterchng.com/blog/2024/05/01/why-do-llm-input-tokens-cost-less-than-output-tokens/) |
| Welcome to Model Optimizer (ModelOpt) documentation! | Documentation | NVIDIA | [Link](https://nvidia.github.io/TensorRT-Model-Optimizer/) |
| x.com Meta Agent | Tweet | X/Twitter | - |
| Triton Architecture | Documentation | NVIDIA Triton Inference Server | [Link](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html) |
| TensorRT-LLM Architecture | Documentation | TensorRT-LLM | [Link](https://nvidia.github.io/TensorRT-LLM/architecture/overview.html) |
| What's Really Going On in Machine Learning? Some Minimal Models | Article | Stephen Wolfram | [Link](https://writings.stephenwolfram.com/2024/08/whats-really-going-on-in-machine-learning-some-minimal-models/) |
| Fire-Flyer AI-HPC: A Cost-Effective Software-Hardware Co-Design for Deep Learning | Paper | arXiv | [2408.14158](https://arxiv.org/abs/2408.14158) |
| awesome-dspy | GitHub | tom-doerr | [Link](https://github.com/tom-doerr/awesome-dspy) |
| Azure/kaito: Kubernetes AI Toolchain Operator | GitHub | Azure | [Link](https://github.com/Azure/kaito) |
| TensorRT explained | Article | aijobs.net | [Link](https://aijobs.net/insights/tensorrt-explained/) |
| The Evolution of Multimodal Model Architectures | Paper | arXiv | [2405.17927](https://arxiv.org/abs/2405.17927) |
| Dynamic sparse attention | Tweet | X/Twitter | - |
| $2 H100s: How the GPU Bubble Burst | Article | Eugene Cheah | [Link](https://www.latent.space/p/gpu-bubble) |
| vLLM v0.6.0: 2.7x Throughput Improvement and 5x Latency Reduction | Blog | vLLM | [Link](https://blog.vllm.ai/2024/09/05/perf-update.html) |
| Making Deep Learning go Brrrr From First Principles | Tutorial | - | [Link](https://horace.io/brrr_intro.html) |
| Glow | Framework | - | [Link](https://github.com/pytorch/glow) |
| ML Compilers Part 2: An Overview of Graph Optimizations | Blog | FuzzyWare | [Link](https://uditagarwal.in/ml-compilers-part-2-graph-optimizations/) |
| GPU-Guide: Graphics Processing Unit (GPU) Architecture Guide | GitHub | mikeroyal | [Link](https://github.com/mikeroyal/GPU-Guide) |
| Blog list | Collection | - | - |
| GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models | Paper | arXiv | [2410.05229](https://arxiv.org/abs/2410.05229) |
| Distilling Llama3.1 8B into 1B in torchtune | Tutorial | PyTorch | [Link](https://pytorch.org/blog/llama-into-torchtune/) |
| Archive ‚Ä¢ AI News ‚Ä¢ Buttondown | Newsletter | AI News | [Link](https://buttondown.com/ainews/archive/) |
| Hugging Face ‚Äì Blog | Blog | Hugging Face | [Link](https://huggingface.co/blog) |
| vllm quantization | Documentation | vLLM | [Link](https://docs.vllm.ai/en/latest/features/quantization/index.html) |
| how-to-optim-algorithm-in-cuda: how to optimize some algorithm in cuda | GitHub | BBuf | [Link](https://github.com/BBuf/how-to-optim-algorithm-in-cuda) |
| INTELLECT-1 Release The First Globally Trained 10B Parameter Model | Announcement | Prime Intellect | [Link](https://www.primeintellect.ai/blog/intellect-1-release) |
| INTELLECT_1_Technical_Report.pdf | Technical Report | PrimeIntellect-ai | [Link](https://github.com/PrimeIntellect-ai/prime/blob/main/INTELLECT_1_Technical_Report.pdf) |
| Making WAF ML models go brrr: saving decades of processing time | Blog | Cloudflare | [Link](https://blog.cloudflare.com/making-waf-ai-models-go-brr/) |
| Claude 3.5 Sonnet Insane Coding Ability | Article | - | - |
| AI-Engineering.academy: Mastering Applied AI, One Concept at a Time | GitHub | adithya-s-k | [Link](https://github.com/adithya-s-k/AI-Engineering.academy) |
| Late Takes on OpenAI o1 | Article | - | - |
| Ways to use torch.compile | Blog | ezyang's blog | [Link](https://blog.ezyang.com/2024/11/ways-to-use-torch-compile/) |
| On AI for developer productivity | Article | - | [Link](https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/) |
| Scaling test-time compute | Demo | Hugging Face Space | [Link](https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute) |
| Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters | Paper | arXiv | [2408.03314](https://arxiv.org/abs/2408.03314) |
| Building effective agents | Guide | Anthropic | [Link](https://www.anthropic.com/research/building-effective-agents) |
| 2024 best papers | Collection | - | - |
| Learning CUDA by optimizing softmax: A worklog | Tutorial | Maharshi's blog | [Link](https://maharshi.bearblog.dev/optimizing-softmax-cuda/) |
| Reinforcement learning from AI feedback (RLAIF): Complete overview | Tutorial | SuperAnnotate | [Link](https://www.superannotate.com/blog/reinforcement-learning-from-ai-feedback-rlaif) |
| Agents | Article | - | - |
| Video Generation Models Explosion 2024 | Article | Yen-Chen Lin | [Link](https://yenchenlin.me/blog/2025/01/08/video-generation-models-explosion-2024/) |
| Tenstorrent Blackhole, Grendel, And Buda ‚Äì A Scale Out Architecture | Analysis | SemiAnalysis | [Link](https://semianalysis.com/2022/04/12/tenstorrent-blackhole-grendel-and/) |
| Dario Amodei ‚Äî On DeepSeek and Export Controls | Article | - | [Link](https://www.darioamodei.com/post/on-deepseek-and-export-controls) |
| Foundations of Large Language Models (this is a book) | Book | arXiv | [2501.09223](https://arxiv.org/abs/2501.09223) |
| How multi-node inference works for massive LLMs like DeepSeek-R1 | Blog | Baseten | [Link](https://www.baseten.co/blog/how-multi-node-inference-works-llms-deepseek-r1/) |
| Understanding Peak, Max-Achievable & Delivered FLOPs, Part 1 | Tutorial | ROCm Blogs | [Link](https://rocm.blogs.amd.com/software-tools-optimization/Understanding_Peak_and_Max-Achievable_FLOPS/README.html) |
| LLMËÆ≠ÁªÉÁªàÊûÅÊåáÂçó | The Ultra-Scale Playbook | Guide | Hugging Face Space | [Link](https://huggingface.co/spaces/nanotron/ultrascale-playbook) |
| Minions: Cost-efficient Collaboration Between On-device and Cloud Language Models | Paper | arXiv | [2502.15964](https://arxiv.org/abs/2502.15964) |
| Circuit Tracing: Revealing Computational Graphs in Language Models | Research | - | [Link](https://transformer-circuits.pub/2025/attribution-graphs/methods.html) |
| On the Biology of a Large Language Model | Article | - | - |
| TAO: Using test-time compute to train efficient LLMs without labeled data | Blog | Databricks | [Link](https://www.databricks.com/blog/tao-using-test-time-compute-train-efficient-llms-without-labeled-data) |
| RLHF Book by Nathan Lambert | Book | Nathan Lambert | [Link](https://rlhfbook.com/) |
| CUTLASS Tutorial: Writing GEMM Kernels Using Tensor Memory For NVIDIA¬Æ Blackwell GPUs | Tutorial | Colfax Research | [Link](https://research.colfax-intl.com/cutlass-tutorial-writing-gemm-kernels-using-tensor-memory-for-nvidia-blackwell-gpus/) |
| The Way of Code | Article | Rick Rubin | - |
| Why I No Longer Recommend RAG for Autonomous Coding Agents | Opinion | - | - |
| xAI's Grok 4: The tension of frontier performance with a side of Elon favoritism | Analysis | - | - |
| Awesome-ML-SYS-Tutorial: My learning notes/codes for ML SYS | GitHub | zhaochenyang20 | [Link](https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial) |
| The Ultra-Scale Playbook | Guide | Hugging Face Space | [Link](https://huggingface.co/spaces/nanotron/ultrascale-playbook) |
| TensorRT-LLM Architecture | Documentation | TensorRT-LLM | [Link](https://nvidia.github.io/TensorRT-LLM/architecture/overview.html) |
| A Manual Implementation of Quantization in PyTorch - Single Layer | Tutorial | Hexo | - |
| Measuring the environmental impact of AI inference | Blog | Google Cloud | [Link](https://cloud.google.com/blog/products/infrastructure/measuring-the-environmental-impact-of-ai-inference) |
| How to Think About GPUs | Guide | How To Scale Your Model | - |
| A Primer on LLM Post-Training | Tutorial | PyTorch | [Link](https://pytorch.org/blog/a-primer-on-llm-post-training/) |
| AI 2027 | Prediction | - | - |
| How To Scale Your Model | Guide | - | - |
| Getting Started With CuTe | Documentation | NVIDIA CUTLASS | [Link](https://docs.nvidia.com/cutlass/media/docs/cpp/cute/00_quickstart.html) |
| AMD Data Center GPUs Explained: MI250X, MI300X, MI350X and Beyond | Guide | - | [Link](https://www.bentoml.com/blog/amd-data-center-gpus-mi250x-mi300x-mi350x-and-beyond) |
| GPU L2 Cache Persistence | Blog | simons blog | [Link](https://veitner.bearblog.dev/gpu-l2-cache-persistence/) |
| RedOne: Revealing Domain-specific LLM Post-Training in Social Networking Services | Paper | arXiv | [2507.10605](https://arxiv.org/abs/2507.10605) |
| The Big LLM Architecture Comparison | Article | - | - |
| The Training Imperative | Article | - | - |
| checkpoint-engine: Checkpoint-engine is a simple middleware to update model weights | GitHub | MoonshotAI | [Link](https://github.com/MoonshotAI/checkpoint-engine) |
| Improving Cursor Tab With RL | Blog | Cursor | [Link](https://cursor.com/blog/tab-rl) |
| Paged Attention from First Principles: A View Inside vLLM | Blog | Hamza's Blog | [Link](https://hamzaelshafie.bearblog.dev/paged-attention-from-first-principles-a-view-inside-vllm/) |
| Speculative cascades ‚Äî A hybrid approach for smarter, faster LLM inference | Article | - | [Link](https://research.google/blog/speculative-cascades-a-hybrid-approach-for-smarter-faster-llm-inference/) |
| Cornell Virtual Workshop: Understanding GPU Architecture | Workshop | Cornell | [Link](https://cvw.cac.cornell.edu/gpu-architecture) |
| Disaggregated Inference at Scale with PyTorch & vLLM | Tutorial | PyTorch | [Link](https://pytorch.org/blog/disaggregated-inference-at-scale-with-pytorch-vllm/) |
| SGLang v0.4: Zero-Overhead Batch Scheduler, Cache-Aware Load Balancer | Blog | LMSYS Org | [Link](https://lmsys.org/blog/2024-12-04-sglang-v0-4/) |
| sglang pdf | Document | - | - |
| Tree Attention: Topology-aware Decoding for Long-Context Attention on GPU clusters | Paper | arXiv | [2408.04093](https://arxiv.org/abs/2408.04093) |
| Will Amazon S3 Vectors Kill Vector Databases‚Äîor Save Them? | Article | Zilliz blog | [Link](https://zilliz.com/blog/will-amazon-s3-vectors-kill-vector-databases-or-save-them) |
| Post-training 101 | Tutorial | Tokens for Thoughts | - |
| Online RL for Cursor Tab | Blog | Cursor | [Link](https://cursor.com/blog/tab-rl) |
| Stanford CRFM | Research Group | Stanford | [Link](https://crfm.stanford.edu/) |
| Surprisingly Fast AI-Generated Kernels We Didn't Mean to Publish (Yet) | Research | Stanford Scaling Intelligence Lab | [Link](https://scalingintelligence.stanford.edu/blogs/fastkernels/) |
| Advanced RAG Techniques: an Illustrated Overview | Article | Towards AI | [Link](https://pub.towardsai.net/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6) |
| Modular Manifolds | Research | Thinking Machines Lab | - |
| Inside NVIDIA GPUs: Anatomy of high performance matmul kernels | Tutorial | Aleksa Gordiƒá | [Link](https://www.aleksagordic.com/blog/matmul) |
| Weight Transfer for RL Post-Training in under 2 seconds | Article | - | - |
| Deploying DeepSeek with PD Disaggregation and Large-Scale Expert Parallelism on 96 H100 GPUs | Blog | LMSYS Org | [Link](https://lmsys.org/blog/2025-05-05-large-scale-ep/) |
| LLM evolution | Article | - | - |
| Qwen 3 | Announcement | Qwen | [Link](https://open.substack.com/pub/aibyhand/p/qwen-3?r=3w4d5&utm_medium=ios) |
| flash decoding | Research | - | - |
| Dissecting Batching Effects in GPT Inference | Analysis | - | [Link](https://le.qun.ch/en/blog/2023/05/13/transformer-batching/) |
| How to think about GPU | Guide | - | - |
