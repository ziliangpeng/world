# Collective Intelligence in Large Language Models: Foundations, Evolution, Breakthroughs, Agentic AI, and Future Directions

*A Comprehensive Research Report*

## Abstract

Collective intelligence (CI)—the ability of groups to outperform individuals—has been studied for decades in distributed AI, swarm systems, ensemble learning, and human organizational theory. The advent of large language models (LLMs) has revitalized this field by enabling networks of intelligent agents that communicate, reason, coordinate, and even exhibit emergent social behaviors.
This report reviews the historical foundations of CI, the rapid progress in LLM-based CI since 2022, major technical breakthroughs, and the emergence of agentic AI as a critical substrate for collective intelligence. We synthesize conceptual principles, modern architectures, empirical findings, and open problems. The report concludes with future directions in human–AI hybrid collective systems and large-scale agent ecosystems.

⸻

1. Introduction

The shift from single, monolithic AI systems toward multi-agent ecosystems represents one of the most significant paradigm transitions in modern AI. While traditional LLM applications treat models as isolated oracles, recent research explores what happens when multiple LLM agents interact—collaborating, debating, specializing, coordinating, or forming emergent structures.

This brings into focus the concept of collective intelligence:

A property of systems where the collective outperforms any individual member through diversity, independence, coordination, and aggregation.

At the same time, the field has seen the rise of agentic AI, which transforms LLMs from passive text generators into autonomous agents capable of planning, acting, using tools, and operating in iterative loops. Agentic AI is essential because collective intelligence cannot arise without capable agents that can meaningfully interact.

This report synthesizes these two fields and clarifies their relationship.

⸻

2. Historical Foundations of Collective Intelligence

2.1 Distributed AI & Multi-Agent Systems (1970s–1990s)

Before LLMs, intelligence was already investigated as a distributed phenomenon.

Foundational works include:
	•	Bond & Gasser (1988), Readings in Distributed Artificial Intelligence
	•	Wooldridge & Jennings (1995), “Intelligent Agents: Theory and Practice”
	•	Lesser (1999), “Multi-Agent Systems: An Emerging Subdiscipline of AI”

These works introduced autonomous agents, coordination, negotiation, and decentralized problem solving.

2.2 Swarm Intelligence (1990s)

Swarm studies revealed how simple local interactions generate sophisticated global behavior.

Key works:
	•	Bonabeau, Dorigo & Theraulaz (1999), Swarm Intelligence
	•	Dorigo & Gambardella (1997), “Ant Colony System”

Principles such as stigmergy, distributed control, and emergent robustness continue to underpin CI research in LLMs.

2.3 Ensemble Learning (1990s–2010s)

Ensembles established mathematically that collections of weaker models (if diverse and independent) outperform individual models.

Key contributions:
	•	Breiman (1996), Bagging
	•	Freund & Schapire (1997), AdaBoost
	•	Breiman (2001), Random Forests
	•	Lakshminarayanan et al. (2017), Deep Ensembles

This line of thinking directly inspires LLM ensemble reasoning (e.g., self-consistency).

2.4 Human Collective Intelligence

Works in organizational science and cognitive psychology show that diversity, independence, and aggregation can produce superior group performance.

Representative works:
	•	Malone & Bernstein (eds.) (2015), Handbook of Collective Intelligence
	•	Surowiecki (2004), The Wisdom of Crowds

These principles will resurface later when designing multi-agent LLM systems.

⸻

3. Agentic AI: The Substrate of Modern Collective Intelligence

Collective intelligence requires agents that can meaningfully contribute to group decisions. Thus, agentic AI is not a separate field but the foundation upon which LLM-based CI is built.

3.1 Definition of Agentic AI

Agentic AI refers to LLM-based systems that possess:
	•	Goal-directed behavior
	•	Planning & decomposition
	•	Iterative reasoning loops (ReAct, CoT, ToT)
	•	Tool use and environment interaction
	•	Memory and self-reflection

An LLM becomes agentic when wrapped in architectures such as ReAct, AutoGPT-style loops, or planner–executor cycles.

3.2 Key Breakthroughs in Agentic AI

ReAct (Yao et al., 2023)
	•	Interleaves Thought → Act → Observe, enabling agents to reason and interact with environments.

Toolformer (Schick et al., 2023)
	•	Demonstrates automatic tool-use acquisition.

Touring Agent Frameworks (2023–2024)
	•	Systems that combine planning, tool APIs, memory, and meta-cognition into standalone AI agents.

3.3 Why Agentic AI Enables Collective Intelligence

Collective intelligence requires agents that can:
	•	hold internal beliefs
	•	communicate
	•	critique or coordinate
	•	perform tasks autonomously
	•	adapt to others

LLMs without agency cannot meaningfully participate in collective behavior beyond naive voting.

Therefore:

Agentic AI is the prerequisite for emergent collective intelligence in AI systems.

Without agency, you only get ensembles.
With agency, you get societies.

⸻

4. Collective Intelligence in the LLM Era (2022–present)

4.1 Chain-of-Thought (CoT) and Internal Multi-Agent Reasoning

Wei et al. (2022) showed that LLMs can be induced to reveal internal reasoning structures.
This inspired internal CI: multiple reasoning trajectories sampled from the same model.

4.2 Self-Consistency (2022)

Yao et al. (2022) demonstrated that sampling diverse CoT paths and aggregating via majority vote significantly improves performance.

This is CI inside a single model, analogous to ensemble learning.

4.3 ReAct and Agent Loops (2022–2023)

ReAct allows LLMs to function as autonomous agents, enabling multi-agent interactions.

4.4 Generative Agents & Emergent Societies (2023)

Park et al. (2023) simulated a town of LLM agents with memory and reflection, resulting in:
	•	emergent norms
	•	social coordination
	•	spontaneous events (e.g., organizing a party)

This is the beginning of AI sociology.

4.5 Multi-Agent LLM Surveys (2024–2025)
	•	Tran et al. (2025), Multi-Agent Collaboration Mechanisms: A Survey of LLMs
	•	Zhang et al. (2024), Large Language Model-Based Multi-Agents: A Survey of Progress and Challenges

These establish multi-agent LLM systems as a distinct research domain.

4.6 Emergence of Social Conventions (2024–2025)

Studies (Takata et al., 2024; others in early 2025) demonstrate emergent:
	•	linguistic conventions
	•	group biases
	•	specialization
	•	identity-like behavior

4.7 Heterogeneous Agent Collectives (2025)

Ye et al. (2025) show that mixing different LLMs (heterogeneity) improves robustness and CI—mirroring human CI theory.

4.8 Evaluating Collective Reasoning (2025)

Li et al. (2025) introduce hidden-profile tasks to measure whether multi-agent LLMs can uncover distributed information—one of the core tests in human group intelligence.

⸻

5. Taxonomy of Collective Intelligence in LLMs

CI in LLMs manifests in three main paradigms:

5.1 Intra-Agent Collective Intelligence (Internal CI)

The model generates multiple reasoning paths internally.

Techniques:
	•	self-consistency
	•	tree-of-thought
	•	ensemble prompting
	•	deliberate multi-sample decoding

5.2 Inter-Agent Collective Intelligence (External CI)

Multiple autonomous agents interact.

Mechanisms:
	•	debate protocols
	•	planner–solver–critic team structures
	•	multi-agent tool-use
	•	distributed memory systems
	•	social simulation environments

Emergent features:
	•	norms
	•	consensus
	•	divisions of labor
	•	coalitions

5.3 Human–AI Hybrid Collective Intelligence

Systems where humans and AI jointly participate in group cognition.

Examples:
	•	human–AI prediction markets
	•	augmented decision committees
	•	organizational intelligence systems

⸻

6. Principles of Collective Intelligence for LLMs

CI depends on three foundational conditions:

6.1 Diversity
	•	different models
	•	different prompts
	•	different roles
	•	different temperatures
	•	different toolsets

6.2 Independence

Prevent correlated errors by:
	•	separate contexts
	•	isolated memories
	•	hidden chain-of-thought

6.3 Aggregation

Effective methods:
	•	majority vote
	•	ranked-choice voting
	•	judge evaluation
	•	constraint intersection
	•	weighted consensus

CI succeeds only when all three conditions are engineered deliberately.

⸻

7. Relationship Between Agentic AI and Collective Intelligence

Concept	Agentic AI	Collective Intelligence
Definition	Autonomous, tool-using LLM agents	Group-level intelligence emerging from agent interactions
Unit	Individual agent	Multi-agent system
Focus	Planning, reasoning, action	Coordination, communication, emergent structure
Emergence	Limited (self-reflection)	High (norms, conventions, specialization)
Dependency	CI requires agentic AI	Agentic AI can exist without CI

Agentic AI → CI is analogous to
Neuron → Brain
Individual → Organization
Worker → Economy

Thus:

Agentic AI is necessary but not sufficient for collective intelligence.
CI is the systemic manifestation of many agentic AIs interacting.

⸻

8. Major Breakthroughs (Across CI + Agentic AI)
	1.	Chain-of-Thought (2022) — Emergent reasoning
	2.	Self-Consistency (2022) — Internal ensembles
	3.	ReAct (2022–2023) — Reasoning + acting loop
	4.	Memory-Augmented Agents (2023) — Long-term behavior
	5.	Generative Agents (2023) — Emergent social structures
	6.	Multi-Agent LLM Surveys (2024–2025) — Field consolidation
	7.	Emergent Conventions (2024–2025) — AI social behavior
	8.	Heterogeneous LLM Agents (2025) — Diversity principle validated
	9.	Collective Reasoning Benchmarks (2025) — Group-level evaluation

⸻

9. Open Problems
	•	How to reliably measure collective intelligence?
	•	How to prevent collusion or unintended social dynamics?
	•	How to maintain useful diversity without chaos?
	•	Can multi-agent systems outperform frontier-level single models?
	•	How to design scalable communication protocols?
	•	How to build safe, interpretable agent ecosystems?

⸻

10. Future Directions
	1.	Hierarchical Multi-Agent Reasoning Systems
	2.	Agent-Based Artificial Organizations
	3.	Large-Scale Human–AI Societies
	4.	Emergent Governance and Norm Formation
	5.	Agent Ecosystems with Self-Regulation
	6.	Mixed-Model Agent Architectures (LLM Ecosystems)

⸻

11. Conclusion

Collective intelligence is emerging as one of the most important paradigms in modern AI, enabled by the convergence of multi-agent LLM systems, agentic architectures, and ensemble-style reasoning.
Agentic AI provides the foundation—planning, memory, tooling, autonomy—while collective intelligence provides the systemic behaviors that arise when many such agents interact.
Together, they represent the transition from single-agent AI to networked, ecosystem-level intelligence, reshaping the future of AI research, applications, and governance.