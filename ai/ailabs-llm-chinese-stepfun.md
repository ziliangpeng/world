# StepFun (阶跃星辰) - Deep Dive

## Company Overview

**StepFun** (阶跃星辰, Step函数), founded by former Microsoft Asia Research Institute leadership, represents the "experienced researcher launching AI startup" archetype. Led by **Jiang Daxin (姜大昕)**, a 16-year Microsoft veteran who headed projects like Bing search engine and Cortana voice assistant, StepFun focuses on "scaling law" principles - achieving AGI through larger models and more diverse data rather than novel architectures. The company released 11 foundation models in its first year, including the Step-2 trillion-parameter MoE model that ranks among China's best-performing LLMs.

---

## Founding Story and History

StepFun was founded in **April 2023** by **Jiang Daxin (姜大昕)**, who brought 16 years of experience leading critical initiatives at Microsoft. Headquartered in Xuhui District, Shanghai (上海徐汇), the company is explicitly focused on achieving AGI (Artificial General Intelligence).

### Jiang Daxin's Background

- Led Bing search engine development
- Headed Cortana intelligent voice assistant project
- Oversaw Azure cognitive services
- Developed natural language understanding systems for Microsoft 365
- Chief Scientist of Microsoft Asia Research Institute

### Founding Team

Includes co-founders with shared Microsoft experience, including Zhu and Jiao Binxing.

### Key Timeline

- **Apr 2023**: Founded by Jiang Daxin and team
- **Mar 2024**: Launched Step series models (Step-1 released)
- **2024**: Released 11 foundation models including Step-1V (multimodal)
- **2024**: Developed Step-2 trillion-parameter MoE model
- **2024**: Series B funding: "several hundred million dollars"
- **Dec 2024**: Secured additional funding in Series B round
- **2025**: Step-Video-T2V text-to-video model released

StepFun's rapid model releases reflect strong belief in scaling law approach.

---

## Funding and Investment

### Funding Information

- **Series B (2024)**: "Several hundred million dollars" reported (exact amount not disclosed)
- **Series B (Dec 2024)**: Additional funding round secured
- **Status**: Achieved unicorn status (>$1B valuation implied)

**Strategic Investment**: Funding indicates confidence in Jiang Daxin's leadership and StepFun's technical approach.

---

## Strategic Positioning

StepFun positions as **"Scaling Law AI - Bigger Models & More Data = AGI"** with philosophy:

1. **Scaling Focus**: Belief that bigger models and diverse data drive AGI
2. **Speed to Market**: Rapid model releases and iterations
3. **Frontier Performance**: Competing with state-of-the-art on benchmarks
4. **Technical Depth**: Led by experienced AI researcher (Jiang Daxin)
5. **Comprehensive Models**: Text, multimodal, video, and audio models
6. **Chinese Excellence**: Focus on building models competitive with Western alternatives

---

## Technical Innovations and Architecture

### Scaling Law Approach

- Emphasis on model scale and data diversity over novel architectures
- MoE architecture for Step-2 (trillion parameters)
- Hybrid dense-sparse models

### Step Series Architecture

- **Step-1**: Dense 130B parameter architecture
- **Step-1V**: Multimodal (100B+ parameters)
- **Step-2**: Trillion-parameter MoE model
- **Step-1 variants**: 8K and 32K context lengths (step-1-8k, step-1-32k)
- **Step-2-16k**: 16K context variant

### Multimodal & Generative Capabilities

- **Step-1V**: Vision-language understanding
- **Step-Video-T2V**: Text-to-video generation
- **Step-Audio**: Speech generation and understanding (experimental)
- Music generation experimental features

---

## Team Background

StepFun's leadership and team:

- **Jiang Daxin (姜大昕)**: Founder, CEO; 16-year Microsoft veteran, Asia Research Institute chief scientist
- **Co-founders**: Zhu (朱) and Jiao Binxing (焦斌星) (shared Microsoft background)
- Engineers and researchers from top AI labs
- Team emphasizing experience over startup inexperience

---

## Model Lineage and Release Timeline

| Release Date | Model | Parameters | Key Features | Open Weights | Technical Report |
|---|---|---|---|---|---|
| Mar 2024 | Step-1 | 130B (dense) | Foundation text model | ❌ | - |
| 2024 | Step-1-8k | 130B | 8K context variant | ❌ | - |
| 2024 | Step-1-32k | 130B | 32K context variant | ❌ | - |
| 2024 | Step-1V | 100B+ | Multimodal vision-language | ❌ | - |
| 2024 | Step-2 | 1T+ (MoE) | Trillion-parameter model | ❌ | - |
| 2024 | Step-2-16k | 1T+ (MoE) | Trillion-param, 16K context | ❌ | - |
| 2025 | Step-Video-T2V | - | Text-to-video generation | ❌ | - |
| 2025 | Step-Audio | - | Speech synthesis & understanding | ❌ | - |
| TBD | 11+ models total | Various | Various specializations | - | - |

---

## Performance and Reception

### Benchmark Performance

- **Step-2-16k**: Ranks 5th globally on LiveBench
- Top performance among Chinese LLMs domestically
- **Step-2**: Approaches GPT-4 level on multiple dimensions:
  - Mathematics: Strong performance
  - Logic: Competitive
  - Programming: Competitive
  - Knowledge: Strong
  - Creativity: Strong
  - Multi-turn dialogue: Strong
- **Instruction following**: 86.57 score on instruction following (high)

### Market Reception

- Recognized as strong contender among Chinese AI startups
- Positive reception for rapid model development pace
- Respect for Jiang Daxin's leadership and Microsoft background
- Step-2 considered among China's best-performing models
- Appreciated for scaling law focus (clear technical philosophy)

---

## Notable Achievements and Stories

1. **Experienced Leadership**: Led by Microsoft veteran with track record on major projects
2. **Rapid Development**: 11 models released within first year
3. **Trillion Parameters**: Step-2 represents first trillion-parameter model by Chinese startup
4. **Scaling Philosophy**: Clear technical positioning based on scaling laws
5. **Competitive Performance**: Step-2 ranks 5th globally, outperforming many Western models
6. **Multimodal & Generative**: Expanding beyond text to video, audio, music
7. **AGI Focus**: Explicit commitment to artificial general intelligence development

---

## Competitive Positioning

### Strengths

- ✅ Experienced leadership with Microsoft pedigree
- ✅ Clear technical philosophy (scaling laws)
- ✅ Rapid iteration and model releases
- ✅ Competitive benchmark performance
- ✅ Comprehensive model portfolio (text, multimodal, video, audio)

### Challenges

- ❌ Limited open-source presence compared to competitors
- ❌ Less consumer-facing brand recognition vs Moonshot/Kimi
- ❌ Smaller ecosystem compared to tech giants (Alibaba, Tencent)
- ❌ Funding disclosure limited (exact amounts not public)

---

## Strategic Outlook

StepFun's focus on scaling laws positions it uniquely in the Chinese LLM landscape. While competitors experiment with novel architectures, StepFun's bet is that AGI emerges from scale and data quality. The rapid release of 11 models in the first year demonstrates operational excellence and clear execution capability.

Key questions for StepFun's future:

1. **Open-Source Strategy**: Will StepFun embrace open-source to compete with DeepSeek, Qwen?
2. **Enterprise vs Consumer**: Which market will StepFun prioritize for monetization?
3. **Differentiation**: As frontier models converge in performance, how will StepFun differentiate?
4. **Capital Efficiency**: Can StepFun's scaling law approach remain cost-competitive with efficient operators like DeepSeek?

The company's Microsoft DNA suggests strong engineering discipline and product focus, but the Chinese AI market increasingly rewards open-source adoption and aggressive pricing—areas where StepFun has yet to make major moves.
